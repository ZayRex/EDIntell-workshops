{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_Keras-EdIntelligence.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punLo1rFYd23"
      },
      "source": [
        "Welcome everyone, this will be the Introduction to Keras workshop orgainised by EdIntelligence. My name is Naman Makkar and I will be taking you through a tour of one of the most popular deep learning libraries out there.\r\n",
        "In this workshop we will be covering applications of keras in computer vision on the MNIST dataset to carry out handwritten digit recognition using Neural Networks.\r\n",
        "This is the documentation for keras - [Keras](https://keras.io/)\r\n",
        "\r\n",
        "We expect the viewers to have some basic information regarding the functioning of Neural Networks like Forward Propagation, Back propagation, activation functions, the 3 types of layers - Input,Hidden,Output etc.\r\n",
        "\r\n",
        "This is a good resource for studying forward and backward propagation in a Neural Network - [Forward and Backward Propagaton](https://ja.d2l.ai/chapter_deep-learning-basics/backprop.html?fbclid=IwAR1Tv-mF4zRO8oycVMl1ALFJrUcOJSuYIowo7mdXBjdRYSMKEqatte4sRPg)\r\n",
        "\r\n",
        "Another excellent resource is - [Working of a Multi Layered Neural Network](https://www.inf.ed.ac.uk/teaching/courses/asr/2013-14/asr08a-nnDetails.pdf?fbclid=IwAR2yIyi8VZSPWa7xRY7enrLK0PWHvRj--5AbLbGHceCc4iDY9ba-WvdoGTg)\r\n",
        "\r\n",
        "We highly recommend that viewers who aren't familiar with the working of a neural network kindly look into these sources.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KvbwjqUOCd4T",
        "outputId": "525e6878-daea-4f9e-d55f-67f5e4f212b7"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWiZBWLZjExn"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D, Dropout, Dense, Flatten, BatchNormalization, MaxPooling2D\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "from keras.optimizers import Adam\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ioNh8phEdNJ"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dfnKXI3pEpu3",
        "outputId": "a201ff89-8169-4113-bb3f-1f3aed75890b"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.imshow(x_train[4], cmap= plt.cm.binary)\r\n",
        "plt.show()\r\n",
        "x_train[4].shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0U6Qi2TqXPM"
      },
      "source": [
        "This is the documentation for ImageDataGenerator - [Keras-ImageDataGenerator](https://keras.io/api/preprocessing/image/)\r\n",
        "It is used for the purpose of image augmentation which helps us train our model on a variety of augmented images and ensures that we train on a diverse dataset and do not end up over-generalising on a particular image given in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO71RMrN3VCj"
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range = 10, # Degree range for random rotations - Random images will be rotated by 10 degrees\r\n",
        "                             zoom_range = 0.10, # Range for a random zoom - Images will be zoomed in the range [1-zoom_range,1+zoom_range] if the zoom_range is given as a float\r\n",
        "                             width_shift_range = 0.1, # Shifts the image right or left by the fraction of the image width specified as float\r\n",
        "                             height_shift_range = 0.1) # Shifts the image up or down by the fraction of the image height specified as float"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYQWJUw_cnRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd6fb17-7b6c-43cd-e784-0d3676e5d663"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UawhdVUxh1nV"
      },
      "source": [
        "y_test = y_test.reshape(y_test.shape[0],1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5flvAz7h55p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e61d5d-0f07-4e6d-d478-4b94b50a6095"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUWLNCuwHSf"
      },
      "source": [
        "Now we will carry out data augmentation by first normalizing our data in order to get rid of anomalies and irregularities in our dataset.\r\n",
        "Normalization reduces the mean to 0 and standard deviation to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lWaQV1_F1Z3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401bfb1f-2a49-4713-c92c-5812e8a75ade"
      },
      "source": [
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\r\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)\r\n",
        "x_train[4].shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLtcz7jMwvlY"
      },
      "source": [
        "x_train = x_train/255.0\r\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrjmQkdKiwdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b41c97-fbf3-4916-b2cc-9a02b8563250"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARNC7qsWYmyp"
      },
      "source": [
        "Important to make x_train 4 dimensional since if we take batch size into account in batch gradient descent, \r\n",
        "the 4th dimension will represent the number of samples in the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goXnjGsE8NW7"
      },
      "source": [
        "x_train = x_train.reshape(-1,28,28,1) "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiM0iyMt8TJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fc9da4-c2dd-4516-d8fc-a31316848dc4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWIPdp4Z8VY6"
      },
      "source": [
        "x_test = x_test.reshape(-1,28,28,1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TA_Nn738ac_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb253c3-425c-4d6b-92ac-7c4552b4231d"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csHK1DhDjV9O"
      },
      "source": [
        "y_train = to_categorical(y_train)  \r\n",
        "y_test = to_categorical(y_test)\r\n",
        "#This is done to one-hot encode the training and testing labels"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynUrxul42vPn"
      },
      "source": [
        "x_train2,x_val2,y_train2,y_val2 = train_test_split(x_train,y_train,test_size=0.1) \r\n",
        "# We split our training data into a training and a validation using train_test_split from scikit-learn"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H-WRTp9tlJX"
      },
      "source": [
        "We will now build a fairly simple fully connected neural network\r\n",
        "which is a network in which every neuron in one layer is connected to a neuron in the other layer.\r\n",
        "This is a good resource to understand the differences between a fully connected NN and a Convolutional Neural Network - [Medium - Fully Connected vs CNN](https://medium.com/swlh/fully-connected-vs-convolutional-neural-networks-813ca7bc6ee5#:~:text=%20Fully%20connected%20neural%20network%20%201%20A,such%20networks%20do%20tend%20to%20have...%20More) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWeYd9XRoNzx"
      },
      "source": [
        "model = Sequential() # This allows us to combine a sequence of layers - input layer, output layer and a series of hidden layers into a model\r\n",
        "model.add(Flatten()) # This layer flattens the input being given to it\r\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu',)) # Used to make fully connected layers \r\n",
        "model.add(BatchNormalization()) # Used to normalize the inputs of each layer\r\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu')) # 256 is the number of neurons to be used in the hidden layer\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAWH2vOCs3kb"
      },
      "source": [
        "Different types of activation functions - [Activation Functions](https://en.wikipedia.org/wiki/Activation_function?fbclid=IwAR3shODvQf48fRtJxJU4je0F2GHicFFXR0H0bmj-Urp6N7x5o0eHwsddDH4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfxuHdPjx3WT"
      },
      "source": [
        "Why do we need Batch Normalization ? - [Why Batch Normalization](https://www.machinecurve.com/index.php/2020/01/14/what-is-batch-normalization-for-training-neural-networks/)\r\n",
        "\r\n",
        "Batch Normalization is needed to avoid internal covariate shift.\r\n",
        "Covariate shift basically means that if we train our model to map from x to y, if the distribution of x is changed our model will struggle to map from x to y even though the function that maps x to y remains the same.\r\n",
        "\r\n",
        "For example lets say we have a binary classifier neural network that differentaites between cats and not-cats with cats being given the label 0 and not-cat being given the label 1, if we train our model on only black cats and have cats of different colour in our test set, our model will have trouble classifying coloured cats as cats even though the decision boundary between cat and not-cat remains unchanged.\r\n",
        "\r\n",
        "When training a multi-layered deep-neural network due to backpropagation the following is expected to happen - \r\n",
        "\r\n",
        "*   The distribution of input data for some particular layer depends on all the interactions happening in all the upstream layers.\r\n",
        "*   A change in how one or more of the upstream layer(s) process data will change the input distribution for this layer.\r\n",
        "\r\n",
        "This is called a covariate shift since the hyperparameters of that particular layer keep changing with respect to the upstream layers which slows down training.\r\n",
        "\r\n",
        "Batch Normalization normalizes the input of each layer (mean = 0 and standard deviation = 1) which helps in reducing the covariate shift since the hyperparameter of each hidden layer are no longer as sensitive to change via the upstream layers.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9zdNxcoMO3I"
      },
      "source": [
        "ReLU vs Sigmoid which activation function is best for hidden layers ?\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*   The derivative of the sigmoid function is always smaller than 1, when we have multiple hidden layers, when we keep multiplying these gradients during forward and backward propagation we end up with a product very close to zero, this is the vanishing gradient problem, on the other hand the gradient of ReLU is 0 for x < 0 and 1 for x > 0 since ReLU = max(x,0), therefore, ReLU is the solution to the vanishing gradient problem.\r\n",
        "*   ReLU is more computationally efficient than sigmoid since it only calculates max(x,0) and doesn't need expensive exponential calculations\r\n",
        "*   In practice it gives better convergence results - [Krizhevsky et al](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDUs9n5zrdaI"
      },
      "source": [
        "Softmax vs Sigmoid - When to use which - \r\n",
        "\r\n",
        "Softmax activation function distributes the probability throughout each output node. Therefore, for multi-class classification, we use softmax whereas for binary classification we can use both softmax and sigmoid.\r\n",
        "\r\n",
        "Note - If you use softmax for binary classification, you will need to have 2 neurons in the output layer whereas if you use sigmoid for binary classification, you will need to have only 1 neuron in the output layer.\r\n",
        "\r\n",
        "A good source for further study is - [Softmax vs Sigmoid](https://medium.com/aidevnepal/for-sigmoid-funcion-f7a5da78fec2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ABUpQqsTxtS"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0-tLurXRzff"
      },
      "source": [
        "model.compile helps us define the optimizer, the loss function and the metric. \r\n",
        "\r\n",
        "Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses.\r\n",
        "\r\n",
        "Great resouce for studying optimizers - [Optimizers](https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6)\r\n",
        "\r\n",
        "We can use various optimizers, the purpose of each is to try to reach at the global minimum while doing gradient descent. Here we have used the Adam optimizer which is one of the best optimizers since it allows us to reach very close to the global minimum in a very short time. \r\n",
        "\r\n",
        "Some sources for studying the Adam optimizer - [Adam Optimizer - Towards Data Science](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c) \r\n",
        "\r\n",
        "[Adam](https://machinelearningjourney.com/index.php/2021/01/09/adam-optimizer/ps://)\r\n",
        "\r\n",
        "A loss function is a simple method of evaluating our model. It is needed since the purpose of training the model in gradient descent is to minimize the loss function.\r\n",
        "\r\n",
        "A good source - [Loss Functions](https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/)\r\n",
        "\r\n",
        "Crossentropy loss function tries to minimize the differences between the predicted probability distribution of the model and the probability distribution of the training dataset.\r\n",
        "\r\n",
        "In this case we have used categorical crossentropy as our loss function which is good if we have multiple categories in our data. We use binary crossentropy if we have only 2 labels in our data. We can also use sparse categorical crossentropy for multiple categories in our data. \r\n",
        "The difference between categorical crossentropy and sparse categorical crossentropy is that, in order to use categorical crossentropy, we have to one-hot encode our target variable whereas sparse categorical crossentropy is used when we have our categories labelled as integers - 0,1,2,3....\r\n",
        "\r\n",
        "metrics are a tool for evaluating the performance of our models, here we have used accuracy as our metric but we can also use various loss functions as our metric for the same purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YtS8eZY0BdO"
      },
      "source": [
        "es = EarlyStopping('val_loss', mode = 'min',verbose=1, patience = 5) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQpoKvV20h3g"
      },
      "source": [
        "Early Stopping is used to avoid overfitting on the training dataset since if we keep training our model for multiple epochs, we will end up overfitting on the training dataset. Which means that the predicted probability distribution of our model will be nearly equivalent to the probability distribution of the training dataset and be different from the probability distribution of the test set.\r\n",
        "\r\n",
        "Early Stopping allows us to choose what metric to be monitored - Whether it is validation loss or accuracy, 'mode' allows us to choose if we want the metric to be minimised or maximised and patience decides the number of epochs for which training should continue if there is no improvement in our metric.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZbbU7xBovV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61aaa53a-d9d3-4a37-837c-98cc792cbd73"
      },
      "source": [
        "history = model.fit_generator(datagen.flow(x_train2, y_train2, batch_size=128),validation_data = (x_val2,y_val2), epochs=20, callbacks=[es], verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  3/422 [..............................] - ETA: 14s - loss: 0.2215 - accuracy: 0.9271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 16s 39ms/step - loss: 0.1666 - accuracy: 0.9465 - val_loss: 0.1457 - val_accuracy: 0.9522\n",
            "Epoch 2/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1564 - accuracy: 0.9495 - val_loss: 0.3090 - val_accuracy: 0.9035\n",
            "Epoch 3/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1468 - accuracy: 0.9534 - val_loss: 0.1487 - val_accuracy: 0.9527\n",
            "Epoch 4/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1389 - accuracy: 0.9556 - val_loss: 0.1912 - val_accuracy: 0.9380\n",
            "Epoch 5/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1354 - accuracy: 0.9558 - val_loss: 0.0895 - val_accuracy: 0.9702\n",
            "Epoch 6/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1303 - accuracy: 0.9583 - val_loss: 0.1356 - val_accuracy: 0.9588\n",
            "Epoch 7/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1230 - accuracy: 0.9613 - val_loss: 0.1226 - val_accuracy: 0.9620\n",
            "Epoch 8/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1205 - accuracy: 0.9614 - val_loss: 0.4935 - val_accuracy: 0.8533\n",
            "Epoch 9/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1183 - accuracy: 0.9622 - val_loss: 0.1756 - val_accuracy: 0.9450\n",
            "Epoch 10/20\n",
            "422/422 [==============================] - 16s 39ms/step - loss: 0.1124 - accuracy: 0.9645 - val_loss: 0.0757 - val_accuracy: 0.9765\n",
            "Epoch 11/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1094 - accuracy: 0.9644 - val_loss: 0.1103 - val_accuracy: 0.9677\n",
            "Epoch 12/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.1074 - accuracy: 0.9651 - val_loss: 0.0706 - val_accuracy: 0.9777\n",
            "Epoch 13/20\n",
            "422/422 [==============================] - 16s 39ms/step - loss: 0.1054 - accuracy: 0.9662 - val_loss: 0.0627 - val_accuracy: 0.9788\n",
            "Epoch 14/20\n",
            "422/422 [==============================] - 16s 39ms/step - loss: 0.1048 - accuracy: 0.9664 - val_loss: 0.1243 - val_accuracy: 0.9597\n",
            "Epoch 15/20\n",
            "422/422 [==============================] - 16s 39ms/step - loss: 0.1007 - accuracy: 0.9674 - val_loss: 0.0671 - val_accuracy: 0.9805\n",
            "Epoch 16/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.0992 - accuracy: 0.9689 - val_loss: 0.0831 - val_accuracy: 0.9763\n",
            "Epoch 17/20\n",
            "422/422 [==============================] - 16s 38ms/step - loss: 0.0971 - accuracy: 0.9681 - val_loss: 0.0813 - val_accuracy: 0.9727\n",
            "Epoch 18/20\n",
            "422/422 [==============================] - 16s 39ms/step - loss: 0.0937 - accuracy: 0.9699 - val_loss: 0.0893 - val_accuracy: 0.9717\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG3m_OgwVcy5"
      },
      "source": [
        "What is a batch ? \r\n",
        "\r\n",
        "It is a hyperparameter that decides the number of samples to train with before updating the internal model parameters such as learning rate and model weights.\r\n",
        "A training dataset can be divided into multiple batches. Usually, a large batch size is good for efficiently training our Neural Network, the only drawback being that it uses a lot of memory so if we have a complex Neural Network, forward and backward propagation on a big batch size can be very computationally expensive.\r\n",
        "\r\n",
        "What is an epoch ? \r\n",
        "\r\n",
        "It is a hyperparameter that informs us how many times the model will train on the data. One epoch can be comprised of multiple batches and one epoch means that the model has trained with each sample in the training dataset.\r\n",
        "\r\n",
        "Great Resource - [Batch & Epoch](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGhDB0-eZZI0",
        "outputId": "4c09280b-5da5-408b-b76e-7b4d15356fb5"
      },
      "source": [
        "# history is an object that stores the information regarding the loss value and the metric of the model at each epoch\r\n",
        "print(history.history['loss'])\r\n",
        "print(history.history['val_loss'])\r\n",
        "print(history.history['accuracy'])\r\n",
        "print(history.history['val_accuracy'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.22029535472393036, 0.16455791890621185, 0.12823277711868286, 0.10845056921243668, 0.11725752055644989, 0.09577033668756485, 0.07753323018550873, 0.0850738137960434, 0.07872086763381958, 0.0870414525270462, 0.06721934676170349, 0.07260746508836746, 0.0571884885430336, 0.0638112723827362, 0.06686924397945404, 0.06436244398355484, 0.05560285970568657, 0.0636872723698616, 0.06419152021408081, 0.05688798427581787]\n",
            "[0.8478333353996277, 0.9240740537643433, 0.9377407431602478, 0.9452407360076904, 0.9509259462356567, 0.9562592506408691, 0.9583518505096436, 0.9603888988494873, 0.962925910949707, 0.963962972164154, 0.9650185108184814, 0.9677592515945435, 0.9688518643379211, 0.9698888659477234, 0.9690555334091187, 0.9706296324729919, 0.9720740914344788, 0.9721111059188843, 0.9735184907913208, 0.9733333587646484]\n",
            "[0.937666654586792, 0.950166642665863, 0.9608333110809326, 0.9651666879653931, 0.9645000100135803, 0.968999981880188, 0.9753333330154419, 0.9741666913032532, 0.9754999876022339, 0.9726666808128357, 0.9789999723434448, 0.9776666760444641, 0.9804999828338623, 0.9810000061988831, 0.9801666736602783, 0.981166660785675, 0.9829999804496765, 0.9783333539962769, 0.9806666374206543, 0.9798333048820496]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsTaVr2fAR8W",
        "outputId": "dea60f4a-b070-4fec-826f-403457286183"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test,verbose=1)\r\n",
        "print(test_loss, test_acc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9858\n",
            "0.04695223271846771 0.98580002784729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sk_4QdPPyik"
      },
      "source": [
        "We can save the model architecture and weights in a file like so - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGLrRaFEhQtk",
        "outputId": "7d83732b-f1c2-4c93-d2b3-56d77e42730a"
      },
      "source": [
        "#save model\r\n",
        "model.save('digit_reader.model')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: digit_reader.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efmAER4JPd7g"
      },
      "source": [
        "We can also just save the model weights instead of saving the entire model architecture like so\r\n",
        "Note that if we just save the weights of our model, we can only use the weights file on a model with the exact same architecture as the model we just saved \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wau9JUo4PCxa"
      },
      "source": [
        "model.save_weights(filepath='final_weight.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6hWNZvZPmIW"
      },
      "source": [
        "model.load_weights('final_weight.h5')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87NG1ncJh_yu"
      },
      "source": [
        "loaded_model = keras.models.load_model('digit_reader.model')"
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}